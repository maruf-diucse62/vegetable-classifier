{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2965251,"sourceType":"datasetVersion","datasetId":1817999,"isSourceIdPinned":false}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nOptimized vegetable-classification training script (PyTorch)\nImprovements: label smoothing, AdamW, CosineAnnealingLR, EMA, TTA, AMP, stronger augmentation\nAuthor: For Abdullah (teacher style) - Perfected Version\n\"\"\"\n\nimport os\nimport random\nimport time\nfrom pathlib import Path\nfrom collections import OrderedDict\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom tqdm import tqdm\nfrom PIL import Image\nimport kagglehub\n\n# -----------------------\n# CONFIG\n# -----------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\n# Download dataset\nprint(\"Downloading dataset...\")\npath = kagglehub.dataset_download(\"misrakahmed/vegetable-image-dataset\")\nprint(\"Path to dataset files:\", path)\n\n# User parameters - change these as needed\nDATA_ROOT = path\n\n# Better directory handling - check multiple possible structures\npossible_structures = [\n    (\"Vegetable Images/train\", \"Vegetable Images/validation\", \"Vegetable Images/test\"),\n    (\"train\", \"validation\", \"test\"),\n]\n\nTRAIN_DIR = VAL_DIR = TEST_DIR = None\nfor train_sub, val_sub, test_sub in possible_structures:\n    train_path = os.path.join(DATA_ROOT, train_sub)\n    val_path = os.path.join(DATA_ROOT, val_sub)\n    test_path = os.path.join(DATA_ROOT, test_sub)\n    if all(os.path.exists(p) for p in [train_path, val_path, test_path]):\n        TRAIN_DIR, VAL_DIR, TEST_DIR = train_path, val_path, test_path\n        print(f\"Found dataset structure: {train_sub}\")\n        break\n\nif TRAIN_DIR is None:\n    raise ValueError(f\"Dataset directories not found. Check structure at {DATA_ROOT}\")\n\nBATCH_SIZE = 32\nIMAGE_SIZE = 224\nEPOCHS = 20\nLR = 3e-4\nWEIGHT_DECAY = 1e-2\nNUM_WORKERS = 4\nNUM_CLASSES = None  # will be inferred\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nUSE_AMP = True       # Automatic Mixed Precision (faster & less memory)\nUSE_EMA = True       # Use Exponential Moving Average for final model\nEMA_DECAY = 0.9997\nUSE_TTA = True       # Use test-time augmentation at inference\nTTA_TRANSFORMS = 5   # number of augmented views per test image\n\nOUT_DIR = Path(\"outputs\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\n# -----------------------\n# HELPERS: seed + device info\n# -----------------------\ndef set_seed(seed=SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed()\n\nprint(\"Device:\", DEVICE)\n\n# -----------------------\n# TRANSFORMS (train/val/test)\n# -----------------------\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.1),\n    transforms.RandomApply([\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05)\n    ], p=0.7),\n    transforms.RandomGrayscale(p=0.03),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Validation/test transforms: deterministic\nval_transform = transforms.Compose([\n    transforms.Resize(int(IMAGE_SIZE * 1.15)),\n    transforms.CenterCrop(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# -----------------------\n# DATASET LOADING\n# -----------------------\ntrain_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\nval_ds = datasets.ImageFolder(VAL_DIR, transform=val_transform)\ntest_ds = datasets.ImageFolder(TEST_DIR, transform=val_transform)\n\nclass_names = train_ds.classes\nNUM_CLASSES = len(class_names)\nprint(f\"Classes ({NUM_CLASSES}): {class_names}\")\nprint(f\"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}, Test samples: {len(test_ds)}\")\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, \n                          num_workers=NUM_WORKERS, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, \n                        num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, \n                         num_workers=NUM_WORKERS, pin_memory=True)\n\n# -----------------------\n# MODEL: pretrained convnext_tiny (preferred) or resnet18 fallback\n# -----------------------\ndef create_model(num_classes=NUM_CLASSES):\n    try:\n        # prefer convnext if torchvision version supports it\n        model = models.convnext_tiny(weights='IMAGENET1K_V1')\n        # replace classifier\n        in_f = model.classifier[-1].in_features\n        model.classifier[-1] = nn.Linear(in_f, num_classes)\n        print(\"Using torchvision.convnext_tiny\")\n    except Exception:\n        print(\"convnext not available, using resnet18\")\n        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n        in_f = model.fc.in_features\n        model.fc = nn.Linear(in_f, num_classes)\n    return model\n\nmodel = create_model().to(DEVICE)\n\n# -----------------------\n# EMA (Exponential Moving Average) helper\n# -----------------------\nclass ModelEMA:\n    \"\"\" Maintains exponential moving average of model parameters \"\"\"\n    def __init__(self, model, decay=EMA_DECAY):\n        self.ema = OrderedDict()\n        self.decay = decay\n        for name, param in model.named_parameters():\n            if param.requires_grad:\n                self.ema[name] = param.detach().clone().to('cpu')\n\n    def update(self, model):\n        for name, param in model.named_parameters():\n            if name in self.ema and param.requires_grad:\n                new_v = param.detach().cpu()\n                self.ema[name] = (1.0 - self.decay) * new_v + self.decay * self.ema[name]\n\n    def apply_shadow(self, model):\n        # Save current params, then load ema params into model\n        self.backup = {}\n        for name, param in model.named_parameters():\n            if name in self.ema:\n                self.backup[name] = param.detach().clone()\n                param.data.copy_(self.ema[name].to(param.device))\n\n    def restore(self, model):\n        for name, param in model.named_parameters():\n            if name in self.backup:\n                param.data.copy_(self.backup[name].to(param.device))\n        self.backup = {}\n\nema = ModelEMA(model) if USE_EMA else None\n\n# -----------------------\n# LOSS, OPTIMIZER, SCHEDULER\n# -----------------------\n# use label smoothing inside CrossEntropyLoss (PyTorch >=1.10 supports label_smoothing)\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.05).to(DEVICE)\n\n# AdamW optimizer recommended for modern training\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n\n# Cosine annealing scheduler for smooth decays\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\n# -----------------------\n# TRAIN / VALID functions (with AMP & gradient clipping)\n# -----------------------\nscaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n\ndef train_one_epoch(model, loader, criterion, optimizer, device, epoch, ema_obj=None, max_grad_norm=1.0):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    pbar = tqdm(loader, desc=f\"Train E{epoch}\")\n    for images, labels in pbar:\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast(enabled=USE_AMP):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        # gradient clipping\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n        scaler.step(optimizer)\n        scaler.update()\n\n        # EMA update\n        if ema_obj is not None:\n            ema_obj.update(model)\n\n        preds = outputs.argmax(dim=1)\n        running_loss += loss.item() * images.size(0)\n        correct += (preds == labels).sum().item()\n        total += images.size(0)\n        pbar.set_postfix(loss=f\"{running_loss/total:.4f}\", acc=f\"{correct/total:.4f}\")\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    with torch.no_grad():\n        for images, labels in tqdm(loader, desc=\"Eval\"):\n            images = images.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            preds = outputs.argmax(dim=1)\n            running_loss += loss.item() * images.size(0)\n            correct += (preds == labels).sum().item()\n            total += images.size(0)\n            all_preds.extend(preds.cpu().numpy())\n            all_targets.extend(labels.cpu().numpy())\n    return running_loss/total, correct/total, np.array(all_targets), np.array(all_preds)\n\n# -----------------------\n# TTA inference (properly seeded for reproducibility)\n# -----------------------\ndef tta_evaluate(model, dataset, device, n_tta=TTA_TRANSFORMS):\n    \"\"\"\n    Test-Time Augmentation with proper seeding for reproducibility\n    \"\"\"\n    model.eval()\n    tta_preds = []\n    tta_targets = []\n    \n    print(f\"Running TTA inference with {n_tta} augmentations per image...\")\n    \n    for idx in tqdm(range(len(dataset))):\n        img_path, label = dataset.samples[idx]\n        pil_image = Image.open(img_path).convert(\"RGB\")\n        \n        probs = []\n        for tta_idx in range(n_tta):\n            # Set seed for reproducible TTA\n            seed = SEED + idx * n_tta + tta_idx\n            random.seed(seed)\n            torch.manual_seed(seed)\n            np.random.seed(seed)\n            \n            # Create augmented transform\n            tta_transform = transforms.Compose([\n                transforms.Resize(int(IMAGE_SIZE * 1.1)),\n                transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.9, 1.0)),\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n            ])\n            \n            img_t = tta_transform(pil_image).unsqueeze(0).to(device)\n            with torch.no_grad():\n                out = torch.softmax(model(img_t), dim=1)\n            probs.append(out.cpu().numpy())\n        \n        # Average probabilities across augmentations\n        avg_prob = np.mean(np.vstack(probs), axis=0)\n        pred = np.argmax(avg_prob)\n        tta_preds.append(pred)\n        tta_targets.append(label)\n    \n    # Reset seed\n    set_seed(SEED)\n    \n    return np.array(tta_targets), np.array(tta_preds)\n\n# -----------------------\n# CHECKPOINT helper\n# -----------------------\ndef save_checkpoint(state, filename):\n    torch.save(state, filename)\n    print(f\"Checkpoint saved: {filename}\")\n\n# -----------------------\n# TRAINING LOOP\n# -----------------------\nbest_val_acc = 0.0\nbest_ckpt_path = OUT_DIR / \"best_model.pth\"\nbest_ckpt_ema_path = OUT_DIR / \"best_model_ema.pth\"\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*60)\n\nfor epoch in range(1, EPOCHS + 1):\n    t0 = time.time()\n    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, \n                                           DEVICE, epoch, ema_obj=ema)\n    # Step scheduler after training epoch\n    scheduler.step()\n    \n    # validate with normal weights\n    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n\n    # If using EMA: evaluate EMA-shadow as well (recommended)\n    if ema is not None:\n        ema.apply_shadow(model)\n        val_loss_ema, val_acc_ema, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n        ema.restore(model)\n    else:\n        val_loss_ema, val_acc_ema = val_loss, val_acc\n\n    elapsed = time.time() - t0\n    print(f\"\\nEpoch {epoch}/{EPOCHS} - time: {elapsed:.1f}s\")\n    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n    print(f\"  Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc*100:.2f}%\")\n    if ema is not None:\n        print(f\"  Val EMA Acc: {val_acc_ema*100:.2f}%\")\n\n    # choose checkpoint decision based on EMA val acc if EMA is used\n    current_val_metric = val_acc_ema if ema is not None else val_acc\n\n    if current_val_metric > best_val_acc:\n        best_val_acc = current_val_metric\n        # Save normal model\n        save_checkpoint({\n            \"epoch\": epoch,\n            \"model_state\": model.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n            \"val_acc\": val_acc,\n            \"class_names\": class_names,\n        }, best_ckpt_path)\n        \n        if ema is not None:\n            # Save EMA params into separate checkpoint file\n            ema.apply_shadow(model)\n            save_checkpoint({\n                \"epoch\": epoch,\n                \"model_state\": model.state_dict(),\n                \"optimizer_state\": optimizer.state_dict(),\n                \"val_acc\": val_acc_ema,\n                \"class_names\": class_names,\n            }, best_ckpt_ema_path)\n            ema.restore(model)\n        print(f\"  ✓ New best model (val_acc={best_val_acc:.4f})\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"TRAINING COMPLETE. Best val acc: {best_val_acc:.4f}\")\nprint(\"=\"*60)\n\n# -----------------------\n# FINAL EVALUATION ON TEST SET\n# -----------------------\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL TEST EVALUATION\")\nprint(\"=\"*60)\n\n# prefer EMA checkpoint if exists\nif os.path.exists(best_ckpt_ema_path):\n    ckpt = torch.load(best_ckpt_ema_path, map_location=DEVICE)\n    model.load_state_dict(ckpt[\"model_state\"])\n    print(\"Loaded EMA best checkpoint for final test evaluation.\")\nelse:\n    ckpt = torch.load(best_ckpt_path, map_location=DEVICE)\n    model.load_state_dict(ckpt[\"model_state\"])\n    print(\"Loaded standard best checkpoint for final test evaluation.\")\n\n# Normal forward test evaluation\ntest_loss, test_acc, test_targets, test_preds = evaluate(model, test_loader, criterion, DEVICE)\nprint(f\"\\nStandard Test Results:\")\nprint(f\"  Test Loss: {test_loss:.4f}\")\nprint(f\"  Test Acc:  {test_acc*100:.4f}%\")\n\n# Classification report + confusion matrix\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_targets, test_preds, target_names=class_names, digits=4))\nprint(\"\\nConfusion Matrix:\")\nprint(cm := confusion_matrix(test_targets, test_preds))\n\n# -----------------------\n# OPTIONAL: TTA-based evaluation (if USE_TTA True)\n# -----------------------\nif USE_TTA:\n    print(\"\\n\" + \"=\"*60)\n    print(\"TEST-TIME AUGMENTATION EVALUATION\")\n    print(\"=\"*60)\n    \n    tta_targets, tta_preds = tta_evaluate(model, test_ds, DEVICE, n_tta=TTA_TRANSFORMS)\n    tta_acc = accuracy_score(tta_targets, tta_preds)\n    \n    print(f\"\\nTTA Test Results (with {TTA_TRANSFORMS} augmentations):\")\n    print(f\"  TTA Accuracy: {tta_acc*100:.4f}%\")\n    print(f\"  Improvement:  {(tta_acc - test_acc)*100:+.4f}%\")\n    \n    print(\"\\nTTA Classification Report:\")\n    print(classification_report(tta_targets, tta_preds, target_names=class_names, digits=4))\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL DONE! ✓\")\nprint(\"=\"*60)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:20:59.091008Z","iopub.execute_input":"2025-12-04T19:20:59.091502Z","iopub.status.idle":"2025-12-04T22:07:02.465595Z","shell.execute_reply.started":"2025-12-04T19:20:59.091481Z","shell.execute_reply":"2025-12-04T22:07:02.464801Z"}},"outputs":[{"name":"stdout","text":"Downloading dataset...\nPath to dataset files: /kaggle/input/vegetable-image-dataset\nFound dataset structure: Vegetable Images/train\nDevice: cuda\nClasses (15): ['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\nTrain samples: 15000, Val samples: 3000, Test samples: 3000\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n100%|██████████| 109M/109M [00:00<00:00, 207MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Using torchvision.convnext_tiny\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/2815081326.py:203: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nSTARTING TRAINING\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Train E1:   0%|          | 0/469 [00:00<?, ?it/s]/tmp/ipykernel_47/2815081326.py:215: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=USE_AMP):\nTrain E1: 100%|██████████| 469/469 [07:52<00:00,  1.01s/it, acc=0.9742, loss=0.4010]\nEval: 100%|██████████| 94/94 [00:08<00:00, 11.62it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/20 - time: 488.6s\n  Train Loss: 0.4010, Train Acc: 97.42%\n  Val Loss:   0.3351, Val Acc:   99.27%\n  Val EMA Acc: 82.07%\nCheckpoint saved: outputs/best_model.pth\nCheckpoint saved: outputs/best_model_ema.pth\n  ✓ New best model (val_acc=0.8207)\n","output_type":"stream"},{"name":"stderr","text":"Train E2: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9895, loss=0.3466]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/20 - time: 486.3s\n  Train Loss: 0.3466, Train Acc: 98.95%\n  Val Loss:   0.3451, Val Acc:   98.90%\n  Val EMA Acc: 97.77%\nCheckpoint saved: outputs/best_model.pth\nCheckpoint saved: outputs/best_model_ema.pth\n  ✓ New best model (val_acc=0.9777)\n","output_type":"stream"},{"name":"stderr","text":"Train E3: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9927, loss=0.3354]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.95it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/20 - time: 486.4s\n  Train Loss: 0.3354, Train Acc: 99.27%\n  Val Loss:   0.3196, Val Acc:   99.73%\n  Val EMA Acc: 99.77%\nCheckpoint saved: outputs/best_model.pth\nCheckpoint saved: outputs/best_model_ema.pth\n  ✓ New best model (val_acc=0.9977)\n","output_type":"stream"},{"name":"stderr","text":"Train E4: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9917, loss=0.3384]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.97it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/20 - time: 486.3s\n  Train Loss: 0.3384, Train Acc: 99.17%\n  Val Loss:   0.3158, Val Acc:   99.87%\n  Val EMA Acc: 100.00%\nCheckpoint saved: outputs/best_model.pth\nCheckpoint saved: outputs/best_model_ema.pth\n  ✓ New best model (val_acc=1.0000)\n","output_type":"stream"},{"name":"stderr","text":"Train E5: 100%|██████████| 469/469 [07:51<00:00,  1.00s/it, acc=0.9949, loss=0.3279]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.94it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/20 - time: 486.9s\n  Train Loss: 0.3279, Train Acc: 99.49%\n  Val Loss:   0.3219, Val Acc:   99.70%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E6: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9955, loss=0.3267]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.97it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/20 - time: 486.3s\n  Train Loss: 0.3267, Train Acc: 99.55%\n  Val Loss:   0.3178, Val Acc:   99.80%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E7: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9957, loss=0.3257]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.95it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/20 - time: 486.0s\n  Train Loss: 0.3257, Train Acc: 99.57%\n  Val Loss:   0.3472, Val Acc:   98.97%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E8: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9961, loss=0.3256]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.94it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/20 - time: 485.9s\n  Train Loss: 0.3256, Train Acc: 99.61%\n  Val Loss:   0.3193, Val Acc:   99.80%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E9: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9975, loss=0.3185]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.98it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/20 - time: 486.7s\n  Train Loss: 0.3185, Train Acc: 99.75%\n  Val Loss:   0.3196, Val Acc:   99.73%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E10: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9987, loss=0.3172]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.98it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/20 - time: 486.0s\n  Train Loss: 0.3172, Train Acc: 99.87%\n  Val Loss:   0.3120, Val Acc:   100.00%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E11: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9989, loss=0.3153]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.91it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/20 - time: 486.3s\n  Train Loss: 0.3153, Train Acc: 99.89%\n  Val Loss:   0.3138, Val Acc:   99.93%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E12: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9993, loss=0.3142]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.98it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/20 - time: 486.2s\n  Train Loss: 0.3142, Train Acc: 99.93%\n  Val Loss:   0.3139, Val Acc:   99.93%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E13: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9988, loss=0.3147]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.96it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/20 - time: 485.9s\n  Train Loss: 0.3147, Train Acc: 99.88%\n  Val Loss:   0.3144, Val Acc:   99.93%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E14: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9996, loss=0.3132]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.89it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/20 - time: 486.3s\n  Train Loss: 0.3132, Train Acc: 99.96%\n  Val Loss:   0.3128, Val Acc:   99.97%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E15: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9995, loss=0.3135]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.98it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/20 - time: 486.3s\n  Train Loss: 0.3135, Train Acc: 99.95%\n  Val Loss:   0.3120, Val Acc:   100.00%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E16: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9999, loss=0.3121]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.97it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16/20 - time: 486.3s\n  Train Loss: 0.3121, Train Acc: 99.99%\n  Val Loss:   0.3118, Val Acc:   100.00%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E17: 100%|██████████| 469/469 [07:51<00:00,  1.00s/it, acc=0.9999, loss=0.3122]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.87it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 12.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17/20 - time: 486.8s\n  Train Loss: 0.3122, Train Acc: 99.99%\n  Val Loss:   0.3118, Val Acc:   100.00%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E18: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=1.0000, loss=0.3119]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.95it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 12.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18/20 - time: 486.5s\n  Train Loss: 0.3119, Train Acc: 100.00%\n  Val Loss:   0.3118, Val Acc:   100.00%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E19: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9999, loss=0.3120]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19/20 - time: 486.3s\n  Train Loss: 0.3120, Train Acc: 99.99%\n  Val Loss:   0.3118, Val Acc:   100.00%\n  Val EMA Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"Train E20: 100%|██████████| 469/469 [07:50<00:00,  1.00s/it, acc=0.9999, loss=0.3119]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\nEval: 100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20/20 - time: 486.2s\n  Train Loss: 0.3119, Train Acc: 99.99%\n  Val Loss:   0.3118, Val Acc:   100.00%\n  Val EMA Acc: 100.00%\n\n============================================================\nTRAINING COMPLETE. Best val acc: 1.0000\n============================================================\n\n============================================================\nFINAL TEST EVALUATION\n============================================================\nLoaded EMA best checkpoint for final test evaluation.\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 94/94 [00:09<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nStandard Test Results:\n  Test Loss: 0.5115\n  Test Acc:  99.8667%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Bean     1.0000    1.0000    1.0000       200\nBitter_Gourd     1.0000    0.9900    0.9950       200\nBottle_Gourd     1.0000    0.9950    0.9975       200\n     Brinjal     0.9950    1.0000    0.9975       200\n    Broccoli     1.0000    1.0000    1.0000       200\n     Cabbage     1.0000    0.9950    0.9975       200\n    Capsicum     1.0000    1.0000    1.0000       200\n      Carrot     1.0000    1.0000    1.0000       200\n Cauliflower     0.9950    1.0000    0.9975       200\n    Cucumber     1.0000    1.0000    1.0000       200\n      Papaya     0.9950    1.0000    0.9975       200\n      Potato     1.0000    1.0000    1.0000       200\n     Pumpkin     0.9950    1.0000    0.9975       200\n      Radish     1.0000    1.0000    1.0000       200\n      Tomato     1.0000    1.0000    1.0000       200\n\n    accuracy                         0.9987      3000\n   macro avg     0.9987    0.9987    0.9987      3000\nweighted avg     0.9987    0.9987    0.9987      3000\n\n\nConfusion Matrix:\n[[200   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n [  0 198   0   1   0   0   0   0   0   0   0   0   1   0   0]\n [  0   0 199   0   0   0   0   0   0   0   1   0   0   0   0]\n [  0   0   0 200   0   0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0 200   0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0 199   0   0   1   0   0   0   0   0   0]\n [  0   0   0   0   0   0 200   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0 200   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0 200   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0 200   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0 200   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0 200   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0 200   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0 200   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 200]]\n\n============================================================\nTEST-TIME AUGMENTATION EVALUATION\n============================================================\nRunning TTA inference with 5 augmentations per image...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3000/3000 [02:44<00:00, 18.21it/s]","output_type":"stream"},{"name":"stdout","text":"\nTTA Test Results (with 5 augmentations):\n  TTA Accuracy: 99.9000%\n  Improvement:  +0.0333%\n\nTTA Classification Report:\n              precision    recall  f1-score   support\n\n        Bean     1.0000    1.0000    1.0000       200\nBitter_Gourd     1.0000    0.9950    0.9975       200\nBottle_Gourd     1.0000    0.9950    0.9975       200\n     Brinjal     1.0000    1.0000    1.0000       200\n    Broccoli     1.0000    1.0000    1.0000       200\n     Cabbage     1.0000    0.9950    0.9975       200\n    Capsicum     1.0000    1.0000    1.0000       200\n      Carrot     1.0000    1.0000    1.0000       200\n Cauliflower     0.9950    1.0000    0.9975       200\n    Cucumber     1.0000    1.0000    1.0000       200\n      Papaya     0.9950    1.0000    0.9975       200\n      Potato     1.0000    1.0000    1.0000       200\n     Pumpkin     0.9950    1.0000    0.9975       200\n      Radish     1.0000    1.0000    1.0000       200\n      Tomato     1.0000    1.0000    1.0000       200\n\n    accuracy                         0.9990      3000\n   macro avg     0.9990    0.9990    0.9990      3000\nweighted avg     0.9990    0.9990    0.9990      3000\n\n\n============================================================\nALL DONE! ✓\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7}]}